{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_minigrid.wrappers import *\n",
    "env = gym.make('MiniGrid-MultiRoom-N6-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter \n",
    "\n",
    "from utils.utils import *\n",
    "from utils.zfilter import ZFilter\n",
    "from model import Actor, Critic, Discriminator\n",
    "from train_model import train_actor_critic, train_discrim\n",
    "\n",
    "args = {\n",
    "    'env_name':'Hopper-v2',\n",
    "    'load_model':None,\n",
    "    'render':'stor'\n",
    "}\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='PyTorch GAIL')\n",
    "# parser.add_argument('--env_name', type=str, default=\"Hopper-v2\", \n",
    "#                     help='name of the environment to run')\n",
    "# parser.add_argument('--load_model', type=str, default=None, \n",
    "#                     help='path to load the saved model')\n",
    "# parser.add_argument('--render', action=\"store_true\", default=False, \n",
    "#                     help='if you dont want to render, set this to False')\n",
    "# parser.add_argument('--gamma', type=float, default=0.99, \n",
    "#                     help='discounted factor (default: 0.99)')\n",
    "# parser.add_argument('--lamda', type=float, default=0.98, \n",
    "#                     help='GAE hyper-parameter (default: 0.98)')\n",
    "# parser.add_argument('--hidden_size', type=int, default=100, \n",
    "#                     help='hidden unit size of actor, critic and discrim networks (default: 100)')\n",
    "# parser.add_argument('--learning_rate', type=float, default=3e-4, \n",
    "#                     help='learning rate of models (default: 3e-4)')\n",
    "# parser.add_argument('--l2_rate', type=float, default=1e-3, \n",
    "#                     help='l2 regularizer coefficient (default: 1e-3)')\n",
    "# parser.add_argument('--clip_param', type=float, default=0.2, \n",
    "#                     help='clipping parameter for PPO (default: 0.2)')\n",
    "# parser.add_argument('--discrim_update_num', type=int, default=2, \n",
    "#                     help='update number of discriminator (default: 2)')\n",
    "# parser.add_argument('--actor_critic_update_num', type=int, default=10, \n",
    "#                     help='update number of actor-critic (default: 10)')\n",
    "# parser.add_argument('--total_sample_size', type=int, default=2048, \n",
    "#                     help='total sample size to collect before PPO update (default: 2048)')\n",
    "# parser.add_argument('--batch_size', type=int, default=64, \n",
    "#                     help='batch size to update (default: 64)')\n",
    "# parser.add_argument('--max_iter_num', type=int, default=500,\n",
    "#                     help='maximal number of main iterations (default: 500)')\n",
    "# parser.add_argument('--seed', type=int, default=500,\n",
    "#                     help='random seed (default: 500)')\n",
    "# parser.add_argument('--logdir', type=str, default='logs',\n",
    "#                     help='tensorboardx logs directory')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    env = gym.make('MiniGrid-MultiRoom-N6-v0')\n",
    "    \n",
    "#     env = gym.make(args.env_name)\n",
    "    env.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    num_inputs = env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.shape[0]\n",
    "    running_state = ZFilter((num_inputs,), clip=5)\n",
    "\n",
    "    print('state size:', num_inputs) \n",
    "    print('action size:', num_actions)\n",
    "\n",
    "    actor = Actor(num_inputs, num_actions, args)\n",
    "    critic = Critic(num_inputs, args)\n",
    "    discrim = Discriminator(num_inputs + num_actions, args)\n",
    "\n",
    "    actor_optim = optim.Adam(actor.parameters(), lr=args.learning_rate)\n",
    "    critic_optim = optim.Adam(critic.parameters(), lr=args.learning_rate, \n",
    "                              weight_decay=args.l2_rate) \n",
    "    discrim_optim = optim.Adam(discrim.parameters(), lr=args.learning_rate)\n",
    "    \n",
    "    # load demonstrations\n",
    "    expert_demo, _ = pickle.load(open('./expert_demo/expert_demo.p', \"rb\"))\n",
    "    demonstrations = np.array(expert_demo)\n",
    "    print(\"demonstrations.shape\", demonstrations.shape)\n",
    "    \n",
    "    # writer = SummaryWriter(args.logdir)\n",
    "    \n",
    "    if args.load_model is not None:\n",
    "        saved_ckpt_path = os.path.join(os.getcwd(), 'save_model', str(args.load_model))\n",
    "        ckpt = torch.load(saved_ckpt_path)\n",
    "\n",
    "        actor.load_state_dict(ckpt['actor'])\n",
    "        critic.load_state_dict(ckpt['critic'])\n",
    "        discrim.load_state_dict(ckpt['discrim'])\n",
    "\n",
    "        running_state.rs.n = ckpt['z_filter_n']\n",
    "        running_state.rs.mean = ckpt['z_filter_m']\n",
    "        running_state.rs.sum_square = ckpt['z_filter_s']\n",
    "\n",
    "        print(\"Loaded OK ex. Zfilter N {}\".format(running_state.rs.n))\n",
    "\n",
    "    \n",
    "    episodes = 0    \n",
    "\n",
    "    for iter in range(args.max_iter_num):\n",
    "        actor.eval(), critic.eval()\n",
    "        memory = deque()\n",
    "\n",
    "        steps = 0\n",
    "        scores = []\n",
    "\n",
    "        while steps < args.total_sample_size: \n",
    "            state = env.reset()\n",
    "            score = 0\n",
    "\n",
    "            state = running_state(state)\n",
    "            \n",
    "            for _ in range(10000): \n",
    "                if args.render:\n",
    "                    env.render()\n",
    "\n",
    "                steps += 1\n",
    "\n",
    "                mu, std = actor(torch.Tensor(state).unsqueeze(0))\n",
    "                action = get_action(mu, std)[0]\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                irl_reward = get_reward(discrim, state, action)\n",
    "\n",
    "                if done:\n",
    "                    mask = 0\n",
    "                else:\n",
    "                    mask = 1\n",
    "\n",
    "                memory.append([state, action, irl_reward, mask])\n",
    "\n",
    "                next_state = running_state(next_state)\n",
    "                state = next_state\n",
    "\n",
    "                score += reward\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            episodes += 1\n",
    "            scores.append(score)\n",
    "        \n",
    "        score_avg = np.mean(scores)\n",
    "        print('{} episode score is {:.2f}'.format(episodes, score_avg))\n",
    "        # writer.add_scalar('log/score', float(score_avg), iter)\n",
    "\n",
    "        actor.train(), critic.train(), discrim.train() \n",
    "        train_discrim(discrim, memory, discrim_optim, demonstrations, args)\n",
    "        train_actor_critic(actor, critic, memory, actor_optim, critic_optim, args)\n",
    "\n",
    "        # if iter % 100:\n",
    "        #     score_avg = int(score_avg)\n",
    "\n",
    "        #     model_path = os.path.join(os.getcwd(),'save_model')\n",
    "        #     if not os.path.isdir(model_path):\n",
    "        #         os.makedirs(model_path)\n",
    "\n",
    "        #     ckpt_path = os.path.join(model_path, 'ckpt_'+ str(score_avg)+'.pth.tar')\n",
    "\n",
    "        #     save_checkpoint({\n",
    "        #         'actor': actor.state_dict(),\n",
    "        #         'critic': critic.state_dict(),\n",
    "        #         'discrim': discrim.state_dict(),\n",
    "        #         'z_filter_n':running_state.rs.n,\n",
    "        #         'z_filter_m': running_state.rs.mean,\n",
    "        #         'z_filter_s': running_state.rs.sum_square,\n",
    "        #         'args': args,\n",
    "        #         'score': score_avg\n",
    "        #     }, filename=ckpt_path)\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
